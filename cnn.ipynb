{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Birds Classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of Transfer Learning\n",
    "\n",
    "Transfer learning (TL) is a research problem in machine learning (ML) that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem. For example, knowledge gained while learning to recognize cars could apply when trying to recognize trucks. This area of research bears some relation to the long history of psychological literature on transfer of learning, although formal ties between the two fields are limited. From the practical standpoint, reusing or transferring information from previously learned tasks for the learning of new tasks has the potential to significantly improve the sample efficiency of a reinforcement learning agent.\n",
    "<br><br>\n",
    "Ressource from : [Wikipedia](https://en.wikipedia.org/wiki/Transfer_learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense, Flatten, Activation\n",
    "from tensorflow.keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data starts here, we store the path to the training set into a variable for further referencing.\n",
    "\n",
    "train_path = './dataset/train'\n",
    "test_path = './dataset/test'\n",
    "valid_path = './dataset/valid'\n",
    "\n",
    "birds = np.array(list(os.listdir(train_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick only 20 type of birds to train on\n",
    "nr_birds = 30\n",
    "\n",
    "np.random.shuffle(birds)\n",
    "# slicing the data\n",
    "birds = birds[:nr_birds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'INDIAN ROLLER', 1: 'SHOEBILL', 2: 'HOATZIN', 3: 'NORTHERN GANNET', 4: 'BIRD OF PARADISE', 5: 'IBISBILL', 6: 'EARED PITA', 7: 'SNOWY OWL', 8: 'MAGPIE GOOSE', 9: 'GREAT POTOO', 10: 'HORNBILL', 11: 'LAZULI BUNTING', 12: 'ANNAS HUMMINGBIRD', 13: 'KILLDEAR', 14: 'SCARLET MACAW', 15: 'ELEGANT TROGON', 16: 'CRESTED KINGFISHER', 17: 'GOLDEN EAGLE', 18: 'WHITE CHEEKED TURACO', 19: 'PURPLE FINCH', 20: 'BLUE HERON', 21: 'BAY-BREASTED WARBLER', 22: 'ASHY THRUSHBIRD', 23: 'CERULEAN WARBLER', 24: 'DUSKY LORY', 25: 'GOLDEN PHEASANT', 26: 'COMMON HOUSE MARTIN', 27: 'OKINAWA RAIL', 28: 'ELLIOTS  PHEASANT', 29: 'MYNA'}\n"
     ]
    }
   ],
   "source": [
    "idx_to_name = {i:x for (i,x) in enumerate(birds)}\n",
    "name_to_idx = {x:i for (i,x) in enumerate(birds)}\n",
    "print(idx_to_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to store labels based on the folders.\n",
    "\n",
    "def get_data_labels(path, birds, dimensions):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for bird in birds:\n",
    "        imgs = [cv2.resize(cv2.imread(img), dimensions, interpolation=cv2.INTER_AREA) for img in glob.glob(path + \"/\" + bird + \"/*.jpg\")]\n",
    "        for img in imgs:\n",
    "            data.append(img)\n",
    "            labels.append(name_to_idx[bird])\n",
    "            \n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4289, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "data_train, labels_train = get_data_labels(train_path, idx_to_name.values(), (224,224))\n",
    "data_test, labels_test = get_data_labels(test_path, idx_to_name.values(), (224,224))\n",
    "data_valid, labels_valid = get_data_labels(valid_path, idx_to_name.values(), (224,224))\n",
    "\n",
    "print(data_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    data = data / 255.0\n",
    "    data = data.astype('float32')\n",
    "    return data\n",
    "\n",
    "def one_hot(labels):\n",
    "    labels = np.eye(len(np.unique(labels)))[labels]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = normalize(data_train)\n",
    "data_test = normalize(data_test)\n",
    "data_valid = normalize(data_valid)\n",
    "\n",
    "labels_train = one_hot(labels_train)\n",
    "labels_test = one_hot(labels_test)\n",
    "labels_valid = one_hot(labels_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-01 20:12:37.174318: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-05-01 20:12:37.174456: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "weights_path = \"./dataset/pre-trained/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "base_vgg16 = VGG16(weights=weights_path, include_top=False, input_shape=(224, 224, 3))\n",
    "# base_vgg16.trainable = False\n",
    "base_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Freezing the weights\n",
    "for layer in base_vgg16.layers:\n",
    "    layer.trainable = False\n",
    " \n",
    "base_vgg16.summary();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use “get_layer” method to save the last layer of the network\n",
    "last_layer = base_vgg16.get_layer('block5_pool')\n",
    "# save the output of the last layer to be the input of the next layer\n",
    "last_output = last_layer.output\n",
    "\n",
    "# flatten the classifier input which is output of the last layer of VGG16 model\n",
    "x = Flatten()(last_output)\n",
    "\n",
    "# add our new softmax layer with 3 hidden units\n",
    "x = Dense(nr_birds, activation='softmax', name='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " softmax (Dense)             (None, 30)                752670    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,467,358\n",
      "Trainable params: 752,670\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# instantiate a new_model using keras’s Model class\n",
    "new_model = Model(inputs=base_vgg16.input, outputs=x)\n",
    "\n",
    "# print the new_model summary\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shaun/miniforge3/lib/python3.9/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "new_model.compile(Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-01 20:12:50.563281: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-05-01 20:12:51.253358: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4288/4289 [============================>.] - ETA: 0s - loss: 1.2345 - accuracy: 0.6702"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-01 20:14:50.634647: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4289/4289 [==============================] - 125s 29ms/step - loss: 1.2353 - accuracy: 0.6701 - val_loss: 0.5036 - val_accuracy: 0.8600\n",
      "Epoch 2/30\n",
      "4289/4289 [==============================] - 236s 55ms/step - loss: 0.1841 - accuracy: 0.9550 - val_loss: 0.3578 - val_accuracy: 0.8933\n",
      "Epoch 3/30\n",
      "4289/4289 [==============================] - 282s 66ms/step - loss: 0.0466 - accuracy: 0.9925 - val_loss: 0.3038 - val_accuracy: 0.9133\n",
      "Epoch 4/30\n",
      "4289/4289 [==============================] - 280s 65ms/step - loss: 0.0221 - accuracy: 0.9972 - val_loss: 0.2186 - val_accuracy: 0.9467\n",
      "Epoch 5/30\n",
      "4289/4289 [==============================] - 207s 48ms/step - loss: 0.0081 - accuracy: 0.9986 - val_loss: 0.2607 - val_accuracy: 0.9467\n",
      "Epoch 6/30\n",
      "4289/4289 [==============================] - 192s 45ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.4532 - val_accuracy: 0.8800\n",
      "Epoch 7/30\n",
      "4289/4289 [==============================] - 183s 43ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.3644 - val_accuracy: 0.8933\n",
      "Epoch 8/30\n",
      "4289/4289 [==============================] - 177s 41ms/step - loss: 6.1520e-04 - accuracy: 1.0000 - val_loss: 0.2456 - val_accuracy: 0.9333\n",
      "Epoch 9/30\n",
      "4289/4289 [==============================] - 174s 41ms/step - loss: 1.8749e-04 - accuracy: 1.0000 - val_loss: 0.2851 - val_accuracy: 0.9200\n",
      "Epoch 10/30\n",
      "4289/4289 [==============================] - 169s 39ms/step - loss: 5.6757e-04 - accuracy: 0.9998 - val_loss: 0.3447 - val_accuracy: 0.9267\n",
      "Epoch 11/30\n",
      "4289/4289 [==============================] - 168s 39ms/step - loss: 1.9855e-04 - accuracy: 1.0000 - val_loss: 0.3810 - val_accuracy: 0.9200\n",
      "Epoch 12/30\n",
      "4289/4289 [==============================] - 164s 38ms/step - loss: 9.1926e-05 - accuracy: 1.0000 - val_loss: 0.3689 - val_accuracy: 0.9000\n",
      "Epoch 13/30\n",
      "4289/4289 [==============================] - 162s 38ms/step - loss: 1.0239e-04 - accuracy: 1.0000 - val_loss: 0.4532 - val_accuracy: 0.8867\n",
      "Epoch 14/30\n",
      "4289/4289 [==============================] - 161s 38ms/step - loss: 1.0798e-05 - accuracy: 1.0000 - val_loss: 0.3082 - val_accuracy: 0.9267\n",
      "Epoch 15/30\n",
      "4289/4289 [==============================] - 157s 37ms/step - loss: 2.7433e-05 - accuracy: 1.0000 - val_loss: 0.3094 - val_accuracy: 0.9333\n",
      "Epoch 16/30\n",
      "4289/4289 [==============================] - 157s 36ms/step - loss: 1.5596e-06 - accuracy: 1.0000 - val_loss: 0.2849 - val_accuracy: 0.9400\n",
      "Epoch 17/30\n",
      "4289/4289 [==============================] - 155s 36ms/step - loss: 6.9509e-06 - accuracy: 1.0000 - val_loss: 0.2329 - val_accuracy: 0.9400\n",
      "Epoch 18/30\n",
      "4289/4289 [==============================] - 155s 36ms/step - loss: 5.5512e-06 - accuracy: 1.0000 - val_loss: 0.3129 - val_accuracy: 0.9400\n",
      "Epoch 19/30\n",
      "4289/4289 [==============================] - 155s 36ms/step - loss: 4.0504e-07 - accuracy: 1.0000 - val_loss: 0.3466 - val_accuracy: 0.9267\n",
      "Epoch 20/30\n",
      "4289/4289 [==============================] - 151s 35ms/step - loss: 4.8118e-07 - accuracy: 1.0000 - val_loss: 0.2973 - val_accuracy: 0.9267\n",
      "Epoch 21/30\n",
      "4289/4289 [==============================] - 154s 36ms/step - loss: 1.1101e-07 - accuracy: 1.0000 - val_loss: 0.2959 - val_accuracy: 0.9267\n",
      "Epoch 22/30\n",
      "4289/4289 [==============================] - 152s 35ms/step - loss: 8.4036e-08 - accuracy: 1.0000 - val_loss: 0.2923 - val_accuracy: 0.9333\n",
      "Epoch 23/30\n",
      "4289/4289 [==============================] - 150s 35ms/step - loss: 6.4771e-08 - accuracy: 1.0000 - val_loss: 0.3122 - val_accuracy: 0.9267\n",
      "Epoch 24/30\n",
      "4289/4289 [==============================] - 150s 35ms/step - loss: 4.0882e-08 - accuracy: 1.0000 - val_loss: 0.2965 - val_accuracy: 0.9267\n",
      "Epoch 25/30\n",
      "4289/4289 [==============================] - 148s 35ms/step - loss: 3.0439e-08 - accuracy: 1.0000 - val_loss: 0.2968 - val_accuracy: 0.9333\n",
      "Epoch 26/30\n",
      "4289/4289 [==============================] - 148s 35ms/step - loss: 2.4563e-08 - accuracy: 1.0000 - val_loss: 0.2687 - val_accuracy: 0.9267\n",
      "Epoch 27/30\n",
      "4289/4289 [==============================] - 149s 35ms/step - loss: 2.0710e-08 - accuracy: 1.0000 - val_loss: 0.3047 - val_accuracy: 0.9200\n",
      "Epoch 28/30\n",
      "4289/4289 [==============================] - 148s 34ms/step - loss: 1.6530e-08 - accuracy: 1.0000 - val_loss: 0.2654 - val_accuracy: 0.9267\n",
      "Epoch 29/30\n",
      "4289/4289 [==============================] - 147s 34ms/step - loss: 1.6356e-08 - accuracy: 1.0000 - val_loss: 0.2971 - val_accuracy: 0.9267\n",
      "Epoch 30/30\n",
      "4289/4289 [==============================] - 145s 34ms/step - loss: 1.3255e-08 - accuracy: 1.0000 - val_loss: 0.2801 - val_accuracy: 0.9267\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='birds.model.hdf5', save_best_only=True)\n",
    "\n",
    "history = new_model.fit(data_train, labels_train, steps_per_epoch=len(data_train),\n",
    "validation_data=(data_test, labels_test), validation_steps=3, epochs=30, verbose=1, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAD4CAYAAAATpHZ6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAArMklEQVR4nO3deXwU9fkH8M9DuAPIFRG5UcACRZGIICpUgyIKaEEKXlhFpIoX+qtQrVVqtWo9qqKCYrWtXCIqCopoPYAKJSg3guG+CSDhCBCSPL8/no1Zwia72czu7Ew+79crr+wx+51ndnae+c73O/MdUVUQEZE/VHA7ACIicg6TOhGRjzCpExH5CJM6EZGPMKkTEflIRbdmXL9+fW3evLlbsyci8qTFixfvUdWU4t53Lak3b94c6enpbs2eiMiTRGRTSe+z+YWIyEeY1ImIfIRJnYjIR5jUiYh8hEmdiMhHmNSJiHyESZ2IyEdcO0/di1SBt98G1q+PbPqzzgKuuy62MRERBWNSj9CxY8AttwATJ9pzkZKnLximvnZtoHfvmIZGRPQzJvUI7N0LXH01MG8e8MQTwKhR4ZN6Tg7QoQNw331AWhpQuXJcQiWH5OYC69YBK1bY36pVwJEjzs5DBOjSBRg0CGjRwtmyqfxiUg8jI8Nq2ps3A5MnA7/5TWSfq1wZeP55++xLLwH33x/bOCk6qsCWLcDy5YUJfMUKYPVqOzoDLPm2bAnUquXsvI8eBWbMAP7wB+D884HBg4FrrwVOP93Z+VD5Im7dzi41NVUTfeyX+fOBfv3s8YcfAt26lb6MK6+0Gv7atUCDBs7GV5xdu4CBA4H69a0WeNVVQLVq8Zl3Itu9+8TEvWIFsHIlcOBA4TSNGwPt2wO//KX9b9/e+kaqV49NTBs3AlOmWIVhyRLbgXTvbgm+f3+gXr3YzLc4OTnAmjUnfkc//ACceuqJ30n79kDdus7OW9XWUdEd7IEDQNu2J877zDOBiuW0Sioii1U1tdj3mdRDmzIFGDIEaNoUmDXLfkTRWLsWaNfOynrjDWdjDGXPHuBXv7LO3Fq1gJ07gRo1bOc0aBBw2WXRNwVlZwNVqwIVEvycqUOHTk4MK1ZYwihQr54lqXbtCpNVu3bWB+KWH36w392kSZZYK1YEeva0BB+LJryffjrx+1m+3H6vubn2fsWKQJs29leQbLOyCj9/+uknJtr27YHmzSP7fRQ0bxVdT3v2FE5Tv76tm1q1rPkrI6Owr6pKFeAXvzh5/k2bhm8aLY1DhwqP2JyUnGzbUjSY1EtJFXjySeChh4CLLgLef7/staUHHgCeew5YtAjo1MmZOEPZvx+45BJrOpg502p8X39ttcBp02wjrlPHaoCDBgE9egBJSSeXc/SoJZWiG9ymTVZjbdfu5Nrsaac5uzFFa9Ei23Ht32/Pk5NP3vDbt7ejpkSINxRVYOlSW2+TJ9v3HmstW578HbVpc+KORBXYti300c7Ro9HPu0aNk39P7dvb0UGw7Gzb8RX9XW7dWjhNzZon7qiLK6uo7GzbboJ3cCtW2PLGwquvAsOHR/dZJvVSOH4c+N3vgAkT7FTEN9+0GkFZZWUBrVsDrVoBc+fGJpkcPGi1uu++s3baXr1OfD8nB5gzx5LEBx9YDaRBA2vD7doV+PHHwh/0jz8CeXn2uUqVrPmhfXurGe3dWzjdrl2F5dete+KG2aULcM45zi9nSZYssZ1a7drWn9GhA9CsWeIfWZREFfj2W1uvTm+qNWpYAmzb1h5HKy/PjgyLJtiSiFjnsBO16/37bccSnOyXLwf27SucJiXlxERfs6bV/gumXbcu9FFAWb+b4vToYfFEg0k9Qvv3AwMGAF98Afzxj8BjjzmbfCdMAIYOtVMiBw92rlwAOHwYuOIK2/inTSvsByjOkSPWpDRpktXojx61ZT3jjMIffcEG0KqVJfZQMjNPrrUVtIECtmN5/PHYHp0UWLnSNpSqVW3HyfuvlG+qVukI9fs8fNimqVDBKltFj1DOOCOx2+vDJXWoqit/nTp10kSxcqVq27aqFSuqvvlmbOaRm6t67rmqjRurHjrkXLnZ2aqXXqpaoYLqlCml//yBA6pLlqgePuxMPPn5qps3qz71lGrduqqA6jXXqC5f7kz5oaxdq3raafa3dm3s5kPel5enun696tKlqkeOuB1NdACkawm5tVwn9XXrVG+80RJi7dqqX3wR2/nNm2ff+B//6Ex5x46p9u6tKqL69tvOlOmkrCzVRx9VrVnTYrzuOueT7vr1tqOsX992zkR+50hSB9ALwBoAGQBGhXi/GYAvACwD8BWAxuHKdDOpb9miOmyY1cyrVlV94AHVzMz4zHvwYJvnhg1lKycnx2rAgOq4cY6EFjN79qg++KBqtWqqSUmqt96qunFj2cvdvFm1eXPVOnXsaIOoPChzUgeQBGAdgJYAKgNYCqBtkWneBTAk8PgSAP8KV64bSX3nTtV77lGtUkW1UiXVO+9U3b49vjFs2aJavbrqgAHRl5GbqzpokK29F190LrZY27FD9e67VStXtu9/xIjov//t21VbtVKtVUt10SJn4yRKZE4k9a4AZgc9Hw1gdJFpVgJoEngsAA6EKzeeSX3vXtVRoyyZJiWp3nJL2WvKZTFmjH3zX35Z+s/m5akOGWKff/pppyOLj82bC4+UqlVTvflm1U8/VT1+PLLP795tfSDJyarz58c2VqJE40RSHwDgjaDnNwJ4ucg0EwHcE3j8awAKoF6IsoYBSAeQ3rRp05gvfFaW6mOPWW1OxJo+1qyJ+WzDys5WbdZMtUOHyBOZqnVC3n67rbXHHotZeHGTkWFNMbVq2TLVr6/6u9+pfv217bxC2btX9eyzrQkrmp0ikdfFK6mfDmA6gO8B/B3AVgC1Syo31jX1RYtUGza0Jbz6atVly2I6u1J7912L7dVXw0+7caOdTXL22faZ0aMtwfvFkSOq06erDhxoNXdAtVEj1ZEjVf/3v8Jl3b9f9bzzrPlm9mx3YyZyS1yaX4pMXwPA1nDlxjKpf/CBJYdmzVQXLIjZbMokP1+1e3fVevVU9+07+f0dO1T//nfVrl1tLQGqXbqojh/vr4Re1MGDqhMnqvbta+3ugGrLlqp/+INqt27WZDNjhttRErnHiaReEcB6AC2COkrbFZmmPoAKgcd/ATAmXLmxSOr5+arPP29NLeedZx2jiWzJEjud8u677fmePZa0L7nEXgesiebJJ+3UvfJm3z7VCRNUe/a076NCBTvCISrPnDqlsTeAtYGzYB4KvDYGQF8tbKL5MTDNGwCqhCvT6aR+/LidTVFwsYtTF9PE2vDh1nnbq5fVQgE7q+ORR3jedbCdO1VXrHA7CiL3hUvqvhgm4NAhG6Bq5kwbt/ypp0IPVJWI9uyx8TeqVLFlGDQI6NgxcQebIiJ3hRsmIIFHOIjM9u02XvjSpcArr9iAXF5Sv77dgKNSJW8PPEVEicHTSX3ZMrsJxf79wEcfefdeoE6MBElEBACerRvOng1ceKGdFzJ3rncTOhGRkzyZ1MeNsxp6y5bAggXxH7ebiChReS6pP/us3THkssusht64sdsRERElDs+1qffpY4PfP/FEYg9kT0TkBs+lxdatgaefdjsKIqLE5LnmFyIiKh6TOhGRjzCpExH5CJM6EZGPMKkTEfkIkzoRkY8wqRMR+QiTOhGRjzCpExH5CJM6EZGPMKkTEflIREldRHqJyBoRyRCRUSHebyoiX4rI9yKyTEQ4ujkRkQvCJnURSQIwFsAVANoCGCwibYtM9jCAqaraEcAgAK84HSgREYUXSU29M4AMVV2vqjkAJgPoV2QaBVAr8PgUANudC5GIiCIVSVJvBGBL0POtgdeCPQrgBhHZCmAWgLtCFSQiw0QkXUTSMzMzowiXiIhK4lRH6WAAb6lqYwC9AfxLRE4qW1XHq2qqqqampKQ4NGsiIioQSVLfBqBJ0PPGgdeC3QpgKgCo6rcAqgKo70SAREQUuUiS+iIArUSkhYhUhnWEzigyzWYAlwKAiPwCltTZvkJEFGdhk7qq5gIYAWA2gNWws1xWisgYEekbmOx+ALeJyFIAkwDcrKoaq6CJiCi0iO5RqqqzYB2gwa89EvR4FYBuzoZGRESlxStKiYh8hEmdiMhHmNSJiHyESZ2IyEeY1ImIfIRJnYjIR5jUiYh8hEmdiMhHmNSJiHyESZ2IyEeY1ImIfIRJnYjIR5jUiYh8hEmdiMhHmNSJiHyESZ2IyEeY1ImIfIRJnYjIRyJK6iLSS0TWiEiGiIwK8f7zIrIk8LdWRPY7HikREYUV9h6lIpIEYCyAngC2AlgkIjMC9yUFAKjqfUHT3wWgYwxiJSKiMCKpqXcGkKGq61U1B8BkAP1KmH4wgElOBEdERKUTSVJvBGBL0POtgddOIiLNALQA8J9i3h8mIukikp6ZmVnaWImIKAynO0oHAZimqnmh3lTV8aqaqqqpKSkpDs+aiIgiSerbADQJet448Foog8CmFyIi10SS1BcBaCUiLUSkMixxzyg6kYicBaAOgG+dDZGIiCIVNqmrai6AEQBmA1gNYKqqrhSRMSLSN2jSQQAmq6rGJlQiIgon7CmNAKCqswDMKvLaI0WeP+pcWEREFA1eUUpE5CNM6kREPsKkTkTkI0zqREQ+wqROROQjTOpERD7CpE5E5CNM6kREPsKkTkTkI0zqREQ+wqROROQjTOpERD7CpE5E5CNM6kREPsKkTkTkI0zqREQ+wqROROQjTOpERD4SUVIXkV4iskZEMkRkVDHTDBSRVSKyUkQmOhsmERFFIuw9SkUkCcBYAD0BbAWwSERmqOqqoGlaARgNoJuq/iQip8YqYCIiKl4kNfXOADJUdb2q5gCYDKBfkWluAzBWVX8CAFXd7WyYREQUiUiSeiMAW4Kebw28Fqw1gNYiMl9EFohIr1AFicgwEUkXkfTMzMzoIiYiomI51VFaEUArAD0ADAbwuojULjqRqo5X1VRVTU1JSXFo1kREVCCSpL4NQJOg540DrwXbCmCGqh5X1Q0A1sKSPBERxVEkSX0RgFYi0kJEKgMYBGBGkWk+gNXSISL1Yc0x650Lk4iIIhE2qatqLoARAGYDWA1gqqquFJExItI3MNlsAHtFZBWALwH8n6rujVXQREQUmqiqKzNOTU3V9PR0V+ZNRORVIrJYVVOLe59XlBIR+QiTOhGRjzCpExH5CJM6EZGPMKkTEfkIkzoRkY8wqRMR+QiTOhGRjzCpExH5CJM6EZGPMKkTEfkIkzoRkY8wqRMR+QiTOhGRjzCpExH5CJM6EZGPMKkTEfkIkzoRkY9ElNRFpJeIrBGRDBEZFeL9m0UkU0SWBP6GOh8qERGFEzapi0gSgLEArgDQFsBgEWkbYtIpqnpO4O8Nh+MsdPgwMH9+zIonIvKySGrqnQFkqOp6Vc0BMBlAv9iGVYJnngEuvhj46SfXQiAiSlSRJPVGALYEPd8aeK2o/iKyTESmiUgTR6ILJS0NyM8HvvoqZrMgIvIqpzpKPwLQXFU7AJgD4O1QE4nIMBFJF5H0zMzM6OZ0/vlAjRrA559HHSwRkV9FktS3AQiueTcOvPYzVd2rqscCT98A0ClUQao6XlVTVTU1JSUlmniBSpWA7t2Z1ImIQogkqS8C0EpEWohIZQCDAMwInkBEGgY97QtgtXMhhpCWBqxdC2zeHNPZEBF5Tdikrqq5AEYAmA1L1lNVdaWIjBGRvoHJ7haRlSKyFMDdAG6OVcAALKkDwBdfxHQ2REReI6rqyoxTU1M1PT09ug+rAg0bApdeCrzzjrOBERElMBFZrKqpxb3vzStKRSyhf/65JXgiIgLg1aQOWBPM7t3AihVuR0JElDC8m9QvvdT+8ywYIqKfeTepN20KtG7NzlIioiDeTeqANcF89RVw/LjbkRARJQTvJ/XDh4GFC92OhIgoIXg7qffoAVSo4P129UmTgPXr3Y4isW3cCEyd6nYURAnP20m9Th0gNdXbST0rC7juOuCuu9yOJLHdcQfwm98Au3a5HQlRQvN2UgesCWbBAuDAAbcjic5339n/WbOANWvcjSVRLV8OfPKJPf7Pf9yNhSjB+SOp5+UB33zjdiTRWbzY/leqBLz0kruxJKq//Q2oXh045RRvH5URxYH3k3rXrkC1at7d2NPTgWbNrAnmrbeA/fvdjiixbN0KTJwIDB1qO/A5c3gVMVEJvJ/Uq1YFLrzQu0l98WKgUyfgnnvsTJ4JE9yOKLG88IIl8fvuA3r2BLZsAX780e2oiBKW95M6YDW4lSuBHTvcjqR09u8HMjKss7djR7tN30svAbm5bkeWGLKygPHjgYEDgebNC0fn9OoOnCgO/JPUAe91ohV0knYK3FPk3nuBTZuAGTOK/Ui5Mm4ccPAg8H//Z89btrTkzqROVCx/JPVzzgHq1vXexl7QSVqQ1Pv2taT197+7FlLCOHbMml7S0uwoBrDROdPSbOedl+dqeESJyh9JvUIFbw7Fm55uSbxePXuelASMGGFn8nz/vauhuW7iRGtOK6ilF+jZ05ploh2Ln8jn/JHUAavBbd1qt7nzioJO0mC33gokJ5fv2np+PvDMM8DZZ1sSD3bJJfbfa0dlRHHir6QOeGdj/+knYN066yQNVrs2cPPNNnRAeb16ctYsYPVqq6WLnPhe/frWHOOV9UwUZ/5J6i1bAi1aeGdjL9pJGuzuu4GcHOC11+IbU6J45hmgSRM76yWUtDRg/nw7BZSIThBRUheRXiKyRkQyRGRUCdP1FxEVkWLvnxdTaWnAl19645TAop2kwVq3Bnr3Bl55xToMy5OFC61PYeRIu8o2lLQ0G2557tz4xkbkAWGTuogkARgL4AoAbQEMFpG2IaarCeAeAO6Ng5uWZp1oBQkzkaWn25FF3bqh37/3Xrtd35QpcQ3Ldc88Y01QQ4cWP81FFwFVqnjnqIwojiKpqXcGkKGq61U1B8BkAP1CTPdnAE8BOOpgfKXjpU60UJ2kwdLSgLZtC6+oLA8yMoDp021Exho1ip+uWjWgWzdvrGeiOIskqTcCsCXo+dbAaz8TkXMBNFHVmSUVJCLDRCRdRNIzMzNLHWxY9evbOeuJvrHv22fjpxftJA0mYkMHfP89MG9e/GJz07PPWpNLJMMQp6UBS5eW385komKUuaNURCoAeA7A/eGmVdXxqpqqqqkpKSllnXVoaWnAf/8LZGfHpnwnlNRJGuyGG6x5pjyc3rh7tw1oNmQIcNpp4af36lXERDEWSVLfBqBJ0PPGgdcK1ATQHsBXIrIRQBcAM1ztLM3JSezabUmdpMGqVweGDQPef9/u/ONnY8dap/D9YesG5txz7SYpiX5URhRnkST1RQBaiUgLEakMYBCAnwcnUdUsVa2vqs1VtTmABQD6qqo7l/xdeCFQuXJib+zp6XYKZp064ae94w5rihk7NvZxueXwYeDll22YhDZtIvtMUpL1oXAoXqIThE3qqpoLYASA2QBWA5iqqitFZIyI9I11gKWWnAxccEFiJ/VwnaTBmjQB+vcHXn8dOHQotnE5QRV4+mmrSd9/v512GG6cln/8w/oZfv/70s0rLY1D8RIVEVGbuqrOUtXWqnqGqv4l8NojqnrScIKq2sO1WnqBtDTrYNyzx9UwQtq7F9iwoeRO0qLuvddO1fznP2MWliNUgQceAB580JrAXn7ZhhNu2NCGP/joI+DIkRM/k5trHaQXXGB/peG1q4iJ4sA/V5QGS+ROtEg7SYN16QKcd551mObnxyaussrLA267DXjuOTt7Zdky26lOnWrjt0ybZs0rKSnAgAHAv/9tQyW89571F5S2lg4AZ5zBoXiJivBnUu/UKXHvZ1nQSXruuZF/RsRq62vXArNnxySsMsnJAQYPtrs2/fGPtvOpUAGoWRO49lrgnXeAzEyL/aabgG+/BW680RL87bdbO3qfPqWfL4fiJTqJP5N6xYrAr36VmEk9Pd1qmJF0kgYbMMCaMV54ISZhRS07G+jXD3j3XbtB9JgxJw/CBVjn9WWX2dAHW7bYcAC//z1w5pnAk0/aTiAaBVcRcyheIgB+TeqAbewbNthFPolk8eLStacXqFwZGD4c+OwzS4qJICsLuPxyq4G//nrkpyNWqAB07gw88YQl42uuiT4GL11FTBQH/k7qQGI1V+zda+3HpWlPDzZokP2fPt2xkKK2e7cdDS1cCEyeXPJYLbGUksKheImC+Dept25tN1kYM8bacxNBpBcdFad1a+CXv7TORTdt2WJntfzwA/Dhh8UPkRsvHIqX6Gf+TeoidgrgTz8Bt9ySGBeoRNNJWlT//na17M6dzsRUWj/+aBd47dhhR0FXXOFOHME4FC/Rz/yb1AGgQwfgqaeAjz8GXn3V7Wis/fjMM21o2Wj17287qPffdyysiC1bZsPeZmfbuPUXXRT/GELxwlXEZfHtt3ZFcSJUTCjh+TupA3YXoV69rBNv5Up3Y4m2kzRYu3Z2CmC8m2B27LBOyUqVrEZclqMNp1Wv7t+heCdOBLp3txuSv/yy29GQB/g/qYvY6H+1agHXXQccdWm49z17gE2bom9PLyBitfWvvrKO13gZMcKGKZgzBzjrrPjNN1I9e/prKF5VOzvo+uvtStveve1uUPPnux0ZJTj/J3UAaNDAxhdZtgwYPdqdGMraSRqsf3+72ObDD8teViTee8/OuHnsscRM6EBiX0VcWseP2+icDz1kFZHZs+0CrmbN7GIut/pTyBPKR1IHrKZz11128c6nn8Z//k50khbo2NFuhTdtWtnLCmffPuDOOwsH6EpU555rfRVeb4I5eNCurn3jDUvq//633bqvdm3bse7fb2cbHT/udqSUoMpPUgds9MD27YGbb7bzrOMpPR1o1cqGLyirgiaYzz+3jTyW7r/fmo4mTLArdROVH4bi3bbNOp8//xwYPx54/PETr87t0MEu8po71wZNIwqhfCX1qlWBSZMsEf72t/Hd+J3oJA3Wv7/V1j7+2Lkyi/rsM+uPePBBu01gouvZ07tD8S5fbgO3rVtn6/S220JPd/31dsT5/PN20RdREeUrqQNWU3/mGWDWrPjdeCIzE9i82Zn29AKdOwONGsWuCebQIWvXbdPGBunyAq8OxTtnjp29k59vtfBevUqe/m9/s+lvvdX9M7oo4ZS/pA7YmRy9e9vY3ytWxH5+Be3pTtbUK1Sw2vrs2bG5ecZDD9mOaMIEO8LxgjPOsM5ELyX1f/zDfovNmwMLFkR2RFS5sg1pXKsW8Otf2xg8RAHlM6mL2MZ0yik2ZGysT3MsSOodOzpbbv/+FvusWc6W+9//Ai+9ZB2k3bo5W3YseW0o3jFj7GrnHj2sht6kSdiP/Oz00y2xr1tnfUSJMM7+oUN22i65StSlTqXU1FRNd3u41E8+sVrS3XfbGOCxcs01wKpVwJo1zpabl2cbd48ewJQpzpR59KjtfLKz7SimZk1nyo2XKVNs4LMpU+w+sEeO2DIV/St4vUEDa6eOdyfwwoXWhn7DDcCbb9pFXdF44QXgvvts+OJRoxwNMWKHD1tT5tNP27UT3brZOPnXXuudozwPEZHFqlr8Yb+qhv0D0AvAGgAZAEaFeH84gOUAlgCYB6BtuDI7deqkCeGee1QB1VmzYjePJk1Ur7suNmXffrtqcrJqdrYz5T38sH0fn3ziTHnxtnu3aoUKtgyR/nXsqJqeHt84+/RRrVtX9eDBspWTn6/6m9/YMs+Z40xskTpyRPWFF1QbNLDv8YorVP/yF9VWrex53bqqI0eq/vBDfOMK5+hR1Z073Y4iagDStaR8XdKb9nkkAVgHoCWAygCWFk3aAGoFPe4L4NNw5SZMUj9yRLVDB9VTTy37BhbKrl32NT/7rPNlq9qGDKi+/37Zy1qyRLViRdWbbip7WW6aO1f13XdVP/rIvp+5cy1pr1ihmpGhunWr6t69qocP23SnnWZJceRI1UOHYh/fkiW2zsaMcaa8gwdV27VTrV9fddMmZ8osybFjqq++qtqokS3Hr36lOm9e4ft5eapffKF67bX2eyqYZsoU+6ybdu1SPeccqwjNnetuLFFyIql3BTA76PloAKNLmH4wgE/ClZswSV1V9b//ta/ixRedL3vWLCv766+dL1tVNSfHakQ33FC2co4fV+3UyXZue/Y4E5tX/PSTHfEAqs2axfaoTVV14EDVWrVsvk5Zs8bKTE1VXbVKdeNGS2AHDti6dcLx46r/+Idq8+b2XV1wgSXvkuzYofrEE4WfOfVU1VGjVNets/fz820ncPy4JfyjR+2o89Ahiz0ry7n4N21Sbd1atVo11ZYtVWvUsG3fCbm5Fm8cOJHUBwB4I+j5jQBeDjHdnYEa/RYArYopaxiAdADpTZs2jcsXELFu3VRbtHDuB1Tgz39WFYntCv/tb22DPno0+jKeftp+DlOmOBeX13zzjepZZ9n3MHiwJUWnrV5tv4fRo50v+4MPim9iqlhRtWZN1ZQU1aZNVdu0UT3vPNWrrlIdOtSa3V5+2Y5c5s5V/fHHwiPXvDzViRMtIQKq555rO778/Mhjy8uzJr1+/UrfPNagQdl3tKtXqzZurHrKKXZUsW2bNRPVrKm6cGHZyt6+XbVLF9UqVVRvvVV1+fKylRdGuKQetqNURAYA6KWqQwPPbwRwvqqOKGb66wBcrqpDSio3ITpKg33wgXVoTp1qHTxOufpqu5nEDz84V2ZRs2YBV14JzJxpHb+llZFhN9+4/HIb0jfUPUbLi2PHgL/+1QbTSk4Gnn3Wzi5x6ju5+Wb7jW3aZHdtctqiRbY+jxwJ/5eVZQOg7dplV1iHOoMmORmoVs2uKm7fHvjzn+2etGX5PrZutY7sAwesnAoV7C/U44IB+VassAHNnnjChk0ojcWL7dz/pCQ7Bfjsswvj6N7dOne/+CK660gWLbJtPCvL/k+fbt9tWpp1YPfqFf39d4tR5o5SlL75pQKArHDlJlTzi6rVJFq1stpLaWog4TRurHr99c6VF8rRo1ZTv+WW0n82L0+1e3erwWzb5nRk3rVqleqFFxa2B69dW/Yy169XTUpSve++spfltNxc6zxcskT1009V335b9amnLNabblKdNMl+K27Izla9447Co4Q1ayL/7NdfW228WbPQ63DTJmsaqlNH9bvvShfXO++oVq1qn1+61F7bu1f1yScL+xvatFF95RVH+2rgQPNLRQDrAbRAYUdpuyLTtAp63CfcTDURk7qq6muvOdv+vXOnlffcc86UV5Lrr7e29Zyc0n3uqacsxtdfj01cXpaXpzpunO3wqlRRnTatbOXdfrtq5crceUbr/fftN56crPrWW+ErXx9/bEn3F79Q3bKl+Ok2bLAmqXr1VJctCx9Hbq7qgw/adtO9u2pm5snT5ORYk9V559l0derYZ0qKI0JlTupWBnoDWAtrM38o8NoYAH0Dj/8OYCXslMYviyb9UH8JmdSzs+0Mgj59nClv5kz7ir/5xpnySjJ9us2rNKe1vfyyfebaa509OvGb7dtVzz/fOtairbFv3WoJffhwZ2Mrb7ZssUQK2GnCWVmhp3vnHetH6NQpdNItKiPDatcpKXaWVHGyslSvvNLm/7vfha9E5eerzp+vOmCA9SUkJakOGmRHRFFyJKnH4i8hk7qq6qOP2teyenXZyxozxjrFYnGqZFHZ2VaDiTRpjBtny9mvX+lr9+XR5s1WS+zYMboO6XvvtQ16/XrnYytvcnPtBISkJDuLZcGCE98fO9a2u+7di0/6oaxdq9qwoXXMhtr+1661Wn/FitakUlobNqjef781lf7rX6X/fACTemnt3m2HbLfdVvay+va1H0G8XHut/SBzc0ue7s03bdVfeWXZzpgpb2bMsO/trrtK97ldu+w0uiFDYhJWuTVvnjWbVKyo+te/WnPZ44/bOurTJ7oL8lavtm2oYcMT2+4/+0y1dm1rovnyy7LFfeBAmc7XZ1KPxvDh1oZa1qvOGjUq+/njpTF5cvjmnn/+02oxl11mF15R6dx3n33H770X+WdGj7bvPNGurPSDffusaQNQPfNM+3/DDWU7+ly50pphGjWyZpkXXrCmk1/+MiGOtJjUo7F2rW2EDz8cfRk7dtjX+/zzjoUV1oEDtjO6++7Q70+aZD/OSy5xbliB8ubYMev8OuWUyDbwffvs7IuBA2MeWrmVn28d/cnJ9tt34iydZcusVp6cbNvxNdfEpxk1Akzq0brmGmtDjfZUpI8/tq833pci9+tnp1EW/WG/+661QV58cXwuhfez9estqXfuHP4weswY+x0UnPJGseP0hYNLlljt/09/cu90zhDCJfXyOfRuJB54wO7P+dZbpf/ssWPAc8/ZuNfxvmNQ//52UcWiRYWvffihDTHcpYtdoJScHN+Y/KZFC7uH6P/+Z+POF+fgQRtFsU8fuxUdxZbTI22efbbdRevRRx2/gCiWvBNpvF1wAdC1qyXn0ozNnZdnw6n+5z92P8kaNWIXYyh9+tgwrgV3RJo5066Q7dTJrjyNdzx+NWAAcMcddheimTNDT/Paa1YxKCnxEzmMSb0kDzwArF9vQwhEQtVuLDFtml1eftNNMQ0vpNq17RLl996zS6J//WurJX76qd0ph5zz7LN2JDZkiB0dBTtyxN7v2RM4/3xXwqPyiUm9JP36AWeeafc01QhuJvLII8C4cXazgpEjYx9fcfr3BzZsAK66Cmjb1m4gXbu2e/H4VdWqNobJsWPWvJWbW/jehAk2pgpr6RRnTOolSUqy5LxwITB/fsnTvvgi8PjjwNChNuiQm/r1s/b8s86ymxrXretuPH7WurXtyOfNs7ZXAMjJsbsAXXghcPHFroZH5U/5vp1dJLKzgaZNbQMtrhnmnXesHb1glMd43xotlJUr7Z6XbHKJj6FD7bZ0s2fbDbuHDrXbJfbq5XZk5DPhRmlkUo/En/5kQ46uXg20aXPie7NmWc34oovsMe/JWD5lZwOdOwOZmUD16kC9enYGUnkexphiIlxSZ/NLJO6805oznn/+xNfnz7ezIDp0sFo8E3r5Vb26HaUdPAhs3Ag8/DATOrmCST0Sp55qZzi89ZbdTAAAli+3jsgmTewwm80c1LYtMHEiMHw40Lev29FQOcWkHqmRI60DbOxYO7Pk8sutdvbZZ5b0iQC7+82rr3rqYhXyF/7yItWmjdW+xo4FLrsMOHrUEnqzZm5HRkT0Myb10njgAbuf4fbtdhVhu3ZuR0REdIIEOPfOQ7p1s5sSd+1qf0RECYZJvTREgAcfdDsKIqJiRdT8IiK9RGSNiGSIyKgQ748UkVUiskxEvhARNjQTEbkgbFIXkSQAYwFcAaAtgMEi0rbIZN8DSFXVDgCmAXja6UCJiCi8SGrqnQFkqOp6Vc0BMBlAv+AJVPVLVc0OPF0AoLGzYRIRUSQiSeqNAGwJer418FpxbgXwSag3RGSYiKSLSHpmZmbkURIRUUQcPaVRRG4AkArgmVDvq+p4VU1V1dSUlBQnZ01ERIjs7JdtAJoEPW8ceO0EIpIG4CEA3VX1mDPhERFRaURSU18EoJWItBCRygAGAZgRPIGIdAQwDkBfVd3tfJhERBSJsEldVXMBjAAwG8BqAFNVdaWIjBGRglGLngFQA8C7IrJERGYUUxwREcWQa+Opi0gmgE1Rfrw+gD0OhpMI/LZMflsewH/L5LflAfy3TKGWp5mqFtsp6VpSLwsRSS9pkHgv8tsy+W15AP8tk9+WB/DfMkWzPBzQi4jIR5jUiYh8xKtJfbzbAcSA35bJb8sD+G+Z/LY8gP+WqdTL48k2dSIiCs2rNXUiIgqBSZ2IyEc8l9TDje3uNSKyUUSWBy7aSnc7nmiIyJsisltEVgS9VldE5ojIj4H/ddyMsTSKWZ5HRWRbYD0tEZHebsZYWiLSRES+DNz3YKWI3BN43ZPrqYTl8ex6EpGqIvI/EVkaWKbHAq+3EJGFgZw3JXBlf/HleKlNPTC2+1oAPWGjRS4CMFhVV7kaWBmIyEbYWPSevWBCRC4GcAjAP1W1feC1pwHsU9W/Bna+dVTVE7eNKmZ5HgVwSFX/5mZs0RKRhgAaqup3IlITwGIAVwO4GR5cTyUsz0B4dD2JiABIVtVDIlIJwDwA9wAYCWC6qk4WkdcALFXVV4srx2s19bBju1P8qeo3APYVebkfgLcDj9+GbXCeUMzyeJqq7lDV7wKPD8KG/GgEj66nEpbHs9QcCjytFPhTAJfAbj4ERLCOvJbUSzu2uxcogM9EZLGIDHM7GAc1UNUdgcc7ATRwMxiHjAjcsvFNrzRThCIizQF0BLAQPlhPRZYH8PB6EpEkEVkCYDeAOQDWAdgfGIMLiCDneS2p+9GFqnou7HaBdwYO/X1FrY3PO+18ob0K4AwA5wDYAeBZV6OJkojUAPAegHtV9UDwe15cTyGWx9PrSVXzVPUc2BDnnQGcVdoyvJbUIxrb3UtUdVvg/24A78NWpB/sCrR7FrR/enpIZlXdFdjg8gG8Dg+up0A77XsA3lHV6YGXPbueQi2PH9YTAKjqfgBfAugKoLaIFNz7ImzO81pSDzu2u5eISHKgkwcikgzgMgArSv6UZ8wAMCTweAiAD12MpcwKEl/ANfDYegp0wk0AsFpVnwt6y5Prqbjl8fJ6EpEUEakdeFwNdkLIalhyHxCYLOw68tTZLwAQOEXpBQBJAN5U1b+4G1H0RKQlrHYO2F2oJnpxeURkEoAesGFCdwH4E4APAEwF0BQ2xPJAVfVE52Mxy9MDdkivADYCuD2oLTrhiciFAOYCWA4gP/DyH2Dt0J5bTyUsz2B4dD2JSAdYR2gSrMI9VVXHBPLEZAB1AXwP4IaS7i7nuaRORETF81rzCxERlYBJnYjIR5jUiYh8hEmdiMhHmNSJiHyESZ2IyEeY1ImIfOT/AT8nTn2vdM3dAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['val_accuracy'], 'b')\n",
    "plt.plot(history.history['val_loss'], 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model, data_valid, labels_valid):\n",
    "    predictions = model(data_valid)\n",
    "    wrong = 0\n",
    "    for i, pred in enumerate(predictions):\n",
    "        if( np.argmax(pred) !=  np.argmax(labels_valid[i])):\n",
    "            wrong += 1\n",
    "    return (len(data_valid) - wrong) / len(data_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "# we use the validation data to verify the accuracy\n",
    "accuracy = get_accuracy(new_model, data_valid, labels_valid)\n",
    "print(\"Valid Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9266666666666666\n"
     ]
    }
   ],
   "source": [
    "# we use the test data to verify the accuracy\n",
    "accuracy = get_accuracy(new_model, data_test, labels_test)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-01 21:38:08.738995: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: birds-trained-model/assets\n"
     ]
    }
   ],
   "source": [
    "new_model.save('birds-trained-model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architectures images from [Deep Learning for Vision Systems Book](https://www.manning.com/books/deep-learning-for-vision-systems)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f50f518e30a1733e8e8c8b608de131219c9974acb0d02ce13c65eb2a815a608c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
